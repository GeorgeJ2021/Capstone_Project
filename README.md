# Capstone Project: ANAMIKA, An Emotionally Intelligent Virtual Companion

### Introduction

In today's fast-paced world, mental and emotional well-being are increasingly recognized as critical components of overall health. However, many individuals find it challenging to maintain their mental health amidst the demands of daily life. Our project addresses this need by introducing an emotionally intelligent virtual companion that resembles a cat. This virtual pet is designed to provide users with a comforting and interactive presence. Utilizing face recognition, emotion detection, and speech analysis technologies, the virtual companion can understand and respond to the user's emotional state. By integrating ChatGPT for natural language conversation, DeepGram for text-to-speech and speech-to-text capabilities, and HuggingFace AI for sentiment analysis, we have created a sophisticated system that offers personalized and contextually relevant interactions within Unity Game Engine.

### Project Done By: 
- George Jose Ambooken
- Dyutin Robin
- Nandakishor V
- Praveen K.V

### Features
- **ChatGPT Integration:** Open AI provides APIs for integrating ChatGPT into our virtual companion. By integrating ChatGPT, the virtual companion was able to have natural, free following conversations with the users, and can tailor its responses based on the context of our conversation. This personalization helps create a more individualized and user-centric experience, enhancing satisfaction and retention.
- **Emotion Detection:** Unity provides APIs or third-party plugins/libraries for face detection, such as OpenCV which can be used to identify, and extract faces from the webcam feed. With the help of a pre-trained machine learning model, we can process the captured faces to assign probabilities or scores for each emotion category, which indicates the likelihood of each emotion being expressed in the detected face.
- **Text-To-Speech:** TTS enables the virtual companion to voice the responses generated by ChatGPT making the interaction between the user and companion more dynamic and accessible.
- **Speech-To-Text:** STT enables the companion to understand the auditory input given by the users. This feature helps the users to have a sense of talking to someone rather than just typing it. This will expand the range of interaction modalities and make the experience more user-friendly.
- **Mood Journal:** This feature helps users to track their moods and emotions over time, fostering self-awareness and potentially providing insights into their mood patterns and triggers. It adds a whole new dimension of personal growth and helps to reflect on the companion experience.
- **Parallax Effect:** This visual technique creates an illusion of depth which leads to faux 3D effects. Even though it is not essential for functionalities, the Parallax Effect helps enhance the visual appeal and immersion of the virtual companion.
  
### Project Screenshots:
**Virtual Companion:**

<img src= "https://github.com/GeorgeJ2021/Capstone_Project/assets/90447105/03a8c838-6682-4c53-b7e6-571a08a9034b" width=500 height=250>
<img src= "https://github.com/GeorgeJ2021/Capstone_Project/assets/90447105/538c4d60-059f-4a42-b83e-e4ddba994219" width=500 height=250>

**Mood Journal:**

<img src= "https://github.com/GeorgeJ2021/Capstone_Project/assets/90447105/020961e0-7860-4cb2-b649-6de2e9b59a84" width=500 height=250>
<img src= "https://github.com/GeorgeJ2021/Capstone_Project/assets/90447105/a41780a7-b2b1-4c76-a467-42c694665e41" width=500 height=250>

### Prerequisites
- **Unity editor:** preferably 2022.3.5f1 version or later versions
- **Webcam or camera**
- **ChatGPT API key:** ChatGPT API key needs to be generated and stored as a system environment variable named "OPENAI_API_KEY"
- **DeepGram API key:** DeepGram API key needs to be generated and stored as a system environment variable named "DeepGramAPI"
- **HuggingFace API key:** HuggingFace API key needs to be generated and stored as a system environment variable named "Hugging_Face"
- **Python**
